{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ed034edf","cell_type":"markdown","source":"# **Machine Learning Model Tuning and Evaluation**","metadata":{}},{"id":"75f47f27","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom scipy.stats import randint, uniform\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:48:41.734858Z","iopub.execute_input":"2025-07-13T08:48:41.735036Z","iopub.status.idle":"2025-07-13T08:48:44.706291Z","shell.execute_reply.started":"2025-07-13T08:48:41.735017Z","shell.execute_reply":"2025-07-13T08:48:44.705448Z"}},"outputs":[],"execution_count":1},{"id":"0e4b3c63-3c88-4492-bb03-84b2f829a8d8","cell_type":"code","source":"# Load dataset \nfrom sklearn.datasets import load_wine\nwine = load_wine()\nX = wine.data\ny = wine.target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:48:46.610959Z","iopub.execute_input":"2025-07-13T08:48:46.611568Z","iopub.status.idle":"2025-07-13T08:48:46.710764Z","shell.execute_reply.started":"2025-07-13T08:48:46.611535Z","shell.execute_reply":"2025-07-13T08:48:46.710130Z"}},"outputs":[],"execution_count":2},{"id":"9b23a57d","cell_type":"code","source":"# spliting data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:48:50.348855Z","iopub.execute_input":"2025-07-13T08:48:50.349157Z","iopub.status.idle":"2025-07-13T08:48:50.356177Z","shell.execute_reply.started":"2025-07-13T08:48:50.349132Z","shell.execute_reply":"2025-07-13T08:48:50.355300Z"}},"outputs":[],"execution_count":3},{"id":"b00d09cb-abdc-4154-a33e-b0f4c1cef7e0","cell_type":"code","source":"# Scaling the data set using Standard Scaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:48:53.452184Z","iopub.execute_input":"2025-07-13T08:48:53.452895Z","iopub.status.idle":"2025-07-13T08:48:53.458763Z","shell.execute_reply.started":"2025-07-13T08:48:53.452868Z","shell.execute_reply":"2025-07-13T08:48:53.458080Z"}},"outputs":[],"execution_count":4},{"id":"b6a9727e-659b-4674-a42c-0a3ddb44f5ba","cell_type":"code","source":"# Define models to evaluate\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n    'Decision Tree': DecisionTreeClassifier(random_state=42),\n    'SVM': SVC(random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42),\n    'KNN': KNeighborsClassifier()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T08:49:06.617963Z","iopub.execute_input":"2025-07-13T08:49:06.618780Z","iopub.status.idle":"2025-07-13T08:49:06.623783Z","shell.execute_reply.started":"2025-07-13T08:49:06.618745Z","shell.execute_reply":"2025-07-13T08:49:06.622906Z"}},"outputs":[],"execution_count":5},{"id":"6b3b2154-f896-4076-b79a-fa1f793d1b25","cell_type":"code","source":"# Define hyperparameter grids for GridSearchCV\nparam_grids = {\n    'Random Forest': {\n        'n_estimators': [50, 60, 10],\n        'max_depth': [None, 10, 20, 30],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    },\n    'SVM': {\n        'C': [0.1, 1, 105, 100],\n        'kernel': ['linear', 'rbf', 'poly'],\n        'gamma': ['scale', 'auto']\n    },\n    'Logistic Regression': {\n        'C': [0.001, 0.01, 0.1, 1000, 10, 100],\n        'penalty': ['l1', 'l2', 'elasticnet'],\n        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n    },\n    'KNN': {\n        'n_neighbors': [3, 5, 6, 8, 11],\n        'weights': ['uniform', 'distance'],\n        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    },\n    'Decision Tree': {\n        'max_depth': [None, 15, 25, 30],\n        'min_samples_split': [2, 3, 10],\n        'min_samples_leaf': [1, 2, 9],\n        'criterion': ['gini', 'entropy']\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:14:37.087866Z","iopub.execute_input":"2025-07-13T09:14:37.088254Z","iopub.status.idle":"2025-07-13T09:14:37.094617Z","shell.execute_reply.started":"2025-07-13T09:14:37.088232Z","shell.execute_reply":"2025-07-13T09:14:37.093754Z"}},"outputs":[],"execution_count":21},{"id":"87d501a8","cell_type":"code","source":"# Define parameter distributions for RandomizedSearchCV\nparam_dists = {\n    'Random Forest': {\n        'n_estimators': randint(50, 250),\n        'max_depth': [None] + list(np.arange(5, 50, 5)),\n        'min_samples_split': randint(2, 20),\n        'min_samples_leaf': randint(1, 10)\n    },\n    'SVM': {\n        'C': uniform(0.1, 100),\n        'kernel': ['linear', 'rbf', 'poly'],\n        'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 10))\n    },\n    'Logistic Regression': {\n        'C': uniform(0.01, 150),\n        'penalty': ['l1', 'l2', 'elasticnet'],\n        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n    },\n    'KNN': {\n        'n_neighbors': randint(1, 18),\n        'weights': ['uniform', 'distance'],\n        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    },\n    'Decision Tree': {\n        'max_depth': [None] + list(np.arange(5, 50, 5)),\n        'min_samples_split': randint(2, 20),\n        'min_samples_leaf': randint(1, 10),\n        'criterion': ['gini', 'entropy']\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:14:46.041020Z","iopub.execute_input":"2025-07-13T09:14:46.041303Z","iopub.status.idle":"2025-07-13T09:14:46.053277Z","shell.execute_reply.started":"2025-07-13T09:14:46.041282Z","shell.execute_reply":"2025-07-13T09:14:46.052514Z"}},"outputs":[],"execution_count":22},{"id":"c9e2abaf","cell_type":"code","source":"# Function to evaluate model performance\ndef evaluate_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    \n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    \n    \n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n    \n    return accuracy, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:07:13.642088Z","iopub.execute_input":"2025-07-13T09:07:13.642677Z","iopub.status.idle":"2025-07-13T09:07:13.648139Z","shell.execute_reply.started":"2025-07-13T09:07:13.642655Z","shell.execute_reply":"2025-07-13T09:07:13.647292Z"}},"outputs":[],"execution_count":16},{"id":"0d6e873f","cell_type":"markdown","source":"## Train and evaluate models with GridSearchCV","metadata":{}},{"id":"7d98ac11","cell_type":"code","source":"print(\"=\"*50)\nprint(\"GRID SEARCH CV RESULTS\")\nprint(\"=\"*50)\n\ngrid_results = []\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name} with GridSearchCV...\")\n    start_time = time.time()\n    \n    grid_search = GridSearchCV(model, param_grids[name], cv=3, n_jobs=-1, verbose=0)\n    grid_search.fit(X_train, y_train)\n    \n    print(f\"Best parameters: {grid_search.best_params_}\")\n    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n    \n    print(\"\\nTest set performance:\")\n    accuracy, precision, recall, f1 = evaluate_model(grid_search.best_estimator_, X_test, y_test)\n    \n    training_time = time.time() - start_time\n    print(f\"Training time: {training_time:.2f} seconds\")\n    \n    grid_results.append({\n        'Model': name,\n        'Best Score': grid_search.best_score_,\n        'Accuracy': accuracy,\n        'Precision': precision,\n        'Recall': recall,\n        'F1': f1,\n        'Training Time (s)': training_time\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:14:58.363899Z","iopub.execute_input":"2025-07-13T09:14:58.364740Z","iopub.status.idle":"2025-07-13T09:15:08.900571Z","shell.execute_reply.started":"2025-07-13T09:14:58.364712Z","shell.execute_reply":"2025-07-13T09:15:08.899791Z"}},"outputs":[{"name":"stdout","text":"==================================================\nGRID SEARCH CV RESULTS\n==================================================\n\nTraining Logistic Regression with GridSearchCV...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\nBest cross-validation score: 0.9860\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 1.95 seconds\n\nTraining Decision Tree with GridSearchCV...\nBest parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\nBest cross-validation score: 0.9223\n\nTest set performance:\nAccuracy: 0.9444\nPrecision: 0.9463\nRecall: 0.9444\nF1-Score: 0.9440\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.93      0.93        14\n           1       0.93      1.00      0.97        14\n           2       1.00      0.88      0.93         8\n\n    accuracy                           0.94        36\n   macro avg       0.95      0.93      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\nConfusion Matrix:\n[[13  1  0]\n [ 0 14  0]\n [ 1  0  7]]\nTraining time: 0.21 seconds\n\nTraining SVM with GridSearchCV...\nBest parameters: {'C': 105, 'gamma': 'scale', 'kernel': 'rbf'}\nBest cross-validation score: 0.9789\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 0.10 seconds\n\nTraining Random Forest with GridSearchCV...\nBest parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 60}\nBest cross-validation score: 0.9858\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 8.06 seconds\n\nTraining KNN with GridSearchCV...\nBest parameters: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'}\nBest cross-validation score: 0.9440\n\nTest set performance:\nAccuracy: 0.9444\nPrecision: 0.9494\nRecall: 0.9444\nF1-Score: 0.9436\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.97        14\n           1       1.00      0.86      0.92        14\n           2       0.89      1.00      0.94         8\n\n    accuracy                           0.94        36\n   macro avg       0.94      0.95      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 1 12  1]\n [ 0  0  8]]\nTraining time: 0.22 seconds\n","output_type":"stream"}],"execution_count":23},{"id":"462ae861","cell_type":"markdown","source":"## Train and evaluate models with RandomizedSearchCV","metadata":{}},{"id":"1c57331b","cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"RANDOMIZED SEARCH CV RESULTS\")\nprint(\"=\"*60)\n\nrandom_results = []\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name} with RandomizedSearchCV...\")\n    start_time = time.time()\n    \n    random_search = RandomizedSearchCV(model, param_dists[name], n_iter=20, cv=5, n_jobs=-1, verbose=1, random_state=42)\n    random_search.fit(X_train, y_train)\n    \n    print(f\"Best parameters: {random_search.best_params_}\")\n    print(f\"Best cross-validation score: {random_search.best_score_:.4f}\")\n    \n    print(\"\\nTest set performance:\")\n    accuracy, precision, recall, f1 = evaluate_model(random_search.best_estimator_, X_test, y_test)\n    \n    training_time = time.time() - start_time\n    print(f\"Training time: {training_time:.2f} seconds\")\n    \n    random_results.append({\n        'Model': name,\n        'Best Score': random_search.best_score_,\n        'Accuracy': accuracy,\n        'Precision': precision,\n        'Recall': recall,\n        'F1': f1,\n        'Training Time (s)': training_time\n    })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:15:33.328083Z","iopub.execute_input":"2025-07-13T09:15:33.328797Z","iopub.status.idle":"2025-07-13T09:15:41.932229Z","shell.execute_reply.started":"2025-07-13T09:15:33.328774Z","shell.execute_reply":"2025-07-13T09:15:41.931490Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRANDOMIZED SEARCH CV RESULTS\n============================================================\n\nTraining Logistic Regression with RandomizedSearchCV...\nFitting 5 folds for each of 20 candidates, totalling 100 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best parameters: {'C': 145.49647782429915, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest cross-validation score: 0.9722\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 0.56 seconds\n\nTraining Decision Tree with RandomizedSearchCV...\nFitting 5 folds for each of 20 candidates, totalling 100 fits\nBest parameters: {'criterion': 'gini', 'max_depth': 35, 'min_samples_leaf': 1, 'min_samples_split': 13}\nBest cross-validation score: 0.9224\n\nTest set performance:\nAccuracy: 0.9444\nPrecision: 0.9514\nRecall: 0.9444\nF1-Score: 0.9449\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.93      0.96        14\n           1       0.88      1.00      0.93        14\n           2       1.00      0.88      0.93         8\n\n    accuracy                           0.94        36\n   macro avg       0.96      0.93      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\nConfusion Matrix:\n[[13  1  0]\n [ 0 14  0]\n [ 0  1  7]]\nTraining time: 0.14 seconds\n\nTraining SVM with RandomizedSearchCV...\nFitting 5 folds for each of 20 candidates, totalling 100 fits\nBest parameters: {'C': 2.1584494295802448, 'gamma': 'auto', 'kernel': 'rbf'}\nBest cross-validation score: 0.9719\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 0.12 seconds\n\nTraining Random Forest with RandomizedSearchCV...\nFitting 5 folds for each of 20 candidates, totalling 100 fits\nBest parameters: {'max_depth': 25, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 107}\nBest cross-validation score: 0.9786\n\nTest set performance:\nAccuracy: 1.0000\nPrecision: 1.0000\nRecall: 1.0000\nF1-Score: 1.0000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        14\n           1       1.00      1.00      1.00        14\n           2       1.00      1.00      1.00         8\n\n    accuracy                           1.00        36\n   macro avg       1.00      1.00      1.00        36\nweighted avg       1.00      1.00      1.00        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 0 14  0]\n [ 0  0  8]]\nTraining time: 7.65 seconds\n\nTraining KNN with RandomizedSearchCV...\nFitting 5 folds for each of 20 candidates, totalling 100 fits\nBest parameters: {'algorithm': 'brute', 'n_neighbors': 6, 'weights': 'distance'}\nBest cross-validation score: 0.9648\n\nTest set performance:\nAccuracy: 0.9444\nPrecision: 0.9494\nRecall: 0.9444\nF1-Score: 0.9436\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.97        14\n           1       1.00      0.86      0.92        14\n           2       0.89      1.00      0.94         8\n\n    accuracy                           0.94        36\n   macro avg       0.94      0.95      0.94        36\nweighted avg       0.95      0.94      0.94        36\n\nConfusion Matrix:\n[[14  0  0]\n [ 1 12  1]\n [ 0  0  8]]\nTraining time: 0.13 seconds\n","output_type":"stream"}],"execution_count":24},{"id":"fc225444","cell_type":"code","source":"# Comparing results\ngrid_df = pd.DataFrame(grid_results)\nrandom_df = pd.DataFrame(random_results)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"GRID SEARCH CV SUMMARY\")\nprint(\"=\"*50)\nprint(grid_df.sort_values(by='Best Score', ascending=False))\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"RANDOMIZED SEARCH CV SUMMARY\")\nprint(\"=\"*50)\nprint(random_df.sort_values(by='Best Score', ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:15:45.506428Z","iopub.execute_input":"2025-07-13T09:15:45.507204Z","iopub.status.idle":"2025-07-13T09:15:45.525100Z","shell.execute_reply.started":"2025-07-13T09:15:45.507170Z","shell.execute_reply":"2025-07-13T09:15:45.524221Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nGRID SEARCH CV SUMMARY\n==================================================\n                 Model  Best Score  Accuracy  Precision    Recall        F1  \\\n0  Logistic Regression    0.985963  1.000000   1.000000  1.000000  1.000000   \n3        Random Forest    0.985816  1.000000   1.000000  1.000000  1.000000   \n2                  SVM    0.978871  1.000000   1.000000  1.000000  1.000000   \n4                  KNN    0.944001  0.944444   0.949383  0.944444  0.943604   \n1        Decision Tree    0.922281  0.944444   0.946296  0.944444  0.943997   \n\n   Training Time (s)  \n0           1.949864  \n3           8.058800  \n2           0.097185  \n4           0.215378  \n1           0.208211  \n\n==================================================\nRANDOMIZED SEARCH CV SUMMARY\n==================================================\n                 Model  Best Score  Accuracy  Precision    Recall        F1  \\\n3        Random Forest    0.978571  1.000000   1.000000  1.000000  1.000000   \n0  Logistic Regression    0.972167  1.000000   1.000000  1.000000  1.000000   \n2                  SVM    0.971921  1.000000   1.000000  1.000000  1.000000   \n4                  KNN    0.964778  0.944444   0.949383  0.944444  0.943604   \n1        Decision Tree    0.922414  0.944444   0.951389  0.944444  0.944856   \n\n   Training Time (s)  \n3           7.648502  \n0           0.555815  \n2           0.122511  \n4           0.127421  \n1           0.142984  \n","output_type":"stream"}],"execution_count":25},{"id":"cd3dea6e","cell_type":"code","source":"# Select best model based on F1 score\nbest_grid_model = grid_df.loc[grid_df['F1'].idxmax()]\nbest_random_model = random_df.loc[random_df['F1'].idxmax()]\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"BEST MODEL COMPARISON\")\nprint(\"=\"*50)\nprint(f\"Best GridSearchCV model: {best_grid_model['Model']} with F1-score {best_grid_model['F1']:.4f}\")\nprint(f\"Best RandomizedSearchCV model: {best_random_model['Model']} with F1-score {best_random_model['F1']:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:16:07.883280Z","iopub.execute_input":"2025-07-13T09:16:07.883598Z","iopub.status.idle":"2025-07-13T09:16:07.889849Z","shell.execute_reply.started":"2025-07-13T09:16:07.883577Z","shell.execute_reply":"2025-07-13T09:16:07.888948Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nBEST MODEL COMPARISON\n==================================================\nBest GridSearchCV model: Logistic Regression with F1-score 1.0000\nBest RandomizedSearchCV model: Logistic Regression with F1-score 1.0000\n","output_type":"stream"}],"execution_count":26},{"id":"60ed51d5","cell_type":"code","source":"# Final best model selection\nif best_grid_model['F1'] > best_random_model['F1']:\n    best_model_name = best_grid_model['Model']\n    best_search = 'GridSearchCV'\n    best_score = best_grid_model['F1']\nelse:\n    best_model_name = best_random_model['Model']\n    best_search = 'RandomizedSearchCV'\n    best_score = best_random_model['F1']\n\nprint(f\"\\nOverall best model: {best_model_name} found by {best_search} with F1-score {best_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:16:17.917199Z","iopub.execute_input":"2025-07-13T09:16:17.918023Z","iopub.status.idle":"2025-07-13T09:16:17.923060Z","shell.execute_reply.started":"2025-07-13T09:16:17.917996Z","shell.execute_reply":"2025-07-13T09:16:17.922155Z"}},"outputs":[{"name":"stdout","text":"\nOverall best model: Logistic Regression found by RandomizedSearchCV with F1-score 1.0000\n","output_type":"stream"}],"execution_count":27},{"id":"f34f9091","cell_type":"markdown","source":"## **🧾Conclusion**\nFor this dataset, the most dependable and computationally effective model without sacrificing accuracy or generalization was:\n\n <b>Logistic Regression</b>\n\nAdditionally, the pipeline uses GridSearchCV and RandomizedSearchCV to show off the effectiveness of hyperparameter tuning.\n","metadata":{}},{"id":"e7aae9e0-dd83-4724-bcec-2dbba2ea7425","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}